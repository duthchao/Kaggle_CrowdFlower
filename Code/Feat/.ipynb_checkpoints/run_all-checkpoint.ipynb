{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load run_all.py\n",
    "\n",
    "\"\"\"\n",
    "__file__\n",
    "\n",
    "\trun_all.py\n",
    "\n",
    "__description___\n",
    "\t\n",
    "\tThis file generates all the features in one shot.\n",
    "\n",
    "__author__\n",
    "\n",
    "\tChenglong Chen < c.chenglong@gmail.com >\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "#################\n",
    "## Preprocesss ##\n",
    "#################\n",
    "#### preprocess data\n",
    "cmd = \"python ./preprocess.py\"\n",
    "os.system(cmd)\n",
    "\n",
    "# #### generate kfold\n",
    "# cmd = \"python ./gen_kfold.py\"\n",
    "# os.system(cmd)\n",
    "\n",
    "#######################\n",
    "## Generate features ##\n",
    "#######################\n",
    "#### query id\n",
    "cmd = \"python ./genFeat_id_feat.py\"\n",
    "os.system(cmd)\n",
    "\n",
    "#### counting feat\n",
    "cmd = \"python ./genFeat_counting_feat.py\"\n",
    "os.system(cmd)\n",
    "\n",
    "#### distance feat\n",
    "cmd = \"python ./genFeat_distance_feat.py\"\n",
    "os.system(cmd)\n",
    "\n",
    "#### basic tfidf\n",
    "cmd = \"python ./genFeat_basic_tfidf_feat.py\"\n",
    "os.system(cmd)\n",
    "\n",
    "#### cooccurrence tfidf\n",
    "cmd = \"python ./genFeat_cooccurrence_tfidf_feat.py\"\n",
    "os.system(cmd)\n",
    "\n",
    "\n",
    "#####################\n",
    "## Combine Feature ##\n",
    "#####################\n",
    "#### combine feat\n",
    "cmd = \"python ./combine_feat_[LSA_and_stats_feat_Jun09]_[Low].py\"\n",
    "os.system(cmd)\n",
    "\n",
    "#### combine feat\n",
    "cmd = \"python ./combine_feat_[LSA_svd150_and_Jaccard_coef_Jun14]_[Low].py\"\n",
    "os.system(cmd)\n",
    "\n",
    "#### combine feat\n",
    "cmd = \"python ./combine_feat_[svd100_and_bow_Jun23]_[Low].py\"\n",
    "os.system(cmd)\n",
    "\n",
    "#### combine feat\n",
    "cmd = \"python ./combine_feat_[svd100_and_bow_Jun27]_[High].py\"\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = '''git add -A\n",
    "git commit -m\"add data\"\n",
    "git push'''\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ls\\n       ls'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load preprocess.py\n",
    "\n",
    "\"\"\"\n",
    "__file__\n",
    "\n",
    "    preprocess.py\n",
    "\n",
    "__description__\n",
    "\n",
    "    This file preprocesses data.\n",
    "\n",
    "__author__\n",
    "\n",
    "    Chenglong Chen\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import cPickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nlp_utils import clean_text, pos_tag_text\n",
    "sys.path.append(\"../\")\n",
    "from param_config import config\n",
    "\n",
    "###############\n",
    "## Load Data ##\n",
    "###############\n",
    "print(\"Load data...\")\n",
    "\n",
    "dfTrain = pd.read_csv(config.original_train_data_path).fillna(\"\")\n",
    "dfTest = pd.read_csv(config.original_test_data_path).fillna(\"\")\n",
    "# number of train/test samples\n",
    "num_train, num_test = dfTrain.shape[0], dfTest.shape[0]\n",
    "\n",
    "print(\"Done.\")\n",
    "\n",
    "\n",
    "######################\n",
    "## Pre-process Data ##\n",
    "######################\n",
    "print(\"Pre-process data...\")\n",
    "\n",
    "## insert fake label for test\n",
    "dfTest[\"median_relevance\"] = np.ones((num_test))\n",
    "dfTest[\"relevance_variance\"] = np.zeros((num_test))\n",
    "\n",
    "## insert sample index\n",
    "dfTrain[\"index\"] = np.arange(num_train)\n",
    "dfTest[\"index\"] = np.arange(num_test)\n",
    "\n",
    "## one-hot encode the median_relevance\n",
    "for i in range(config.n_classes):\n",
    "    dfTrain[\"median_relevance_%d\" % (i+1)] = 0\n",
    "    dfTrain[\"median_relevance_%d\" % (i+1)][dfTrain[\"median_relevance\"]==(i+1)] = 1\n",
    "    \n",
    "## query ids\n",
    "qid_dict = dict()\n",
    "for i,q in enumerate(np.unique(dfTrain[\"query\"]), start=1):\n",
    "    qid_dict[q] = i\n",
    "    \n",
    "## insert query id\n",
    "dfTrain[\"qid\"] = map(lambda q: qid_dict[q], dfTrain[\"query\"])\n",
    "dfTest[\"qid\"] = map(lambda q: qid_dict[q], dfTest[\"query\"])\n",
    "\n",
    "## clean text\n",
    "clean = lambda line: clean_text(line, drop_html_flag=config.drop_html_flag)\n",
    "dfTrain = dfTrain.apply(clean, axis=1)\n",
    "dfTest = dfTest.apply(clean, axis=1)\n",
    "\n",
    "print(\"Done.\")\n",
    "\n",
    "\n",
    "###############\n",
    "## Save Data ##\n",
    "###############\n",
    "print(\"Save data...\")\n",
    "\n",
    "with open(config.processed_train_data_path, \"wb\") as f:\n",
    "    cPickle.dump(dfTrain, f, -1)\n",
    "with open(config.processed_test_data_path, \"wb\") as f:\n",
    "    cPickle.dump(dfTest, f, -1)\n",
    "    \n",
    "print(\"Done.\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "## pos tag text\n",
    "dfTrain = dfTrain.apply(pos_tag_text, axis=1)\n",
    "dfTest = dfTest.apply(pos_tag_text, axis=1)\n",
    "with open(config.pos_tagged_train_data_path, \"wb\") as f:\n",
    "    cPickle.dump(dfTrain, f, -1)\n",
    "with open(config.pos_tagged_test_data_path, \"wb\") as f:\n",
    "    cPickle.dump(dfTest, f, -1)\n",
    "print(\"Done.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load genFeat_counting_feat.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load genFeat_distance_feat.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load genFeat_basic_tfidf_feat.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%genFeat_cooccurrence_tfidf_feat.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
